%!TEX root = ../main.tex
\section{Background}
\label{sec:background}

Automated machine learning~(AutoML) research spans over a diverse set of fields. In this section, we first highlight the most relevant families of approaches from the literature. Next, we deepen our discussion on algorithm configuration, the field to which our approach belongs. Finally, we detail \irace to add context to our proposal in Section~\ref{sec:isklearn}.

%Automated algorithm engineering is a growing field that comprehends different tasks, such as selection, configuration, design, and analysis~\cite{BezerraPhD}. The prominent results obtained by these approaches span over a wide range of application domains, such as decision~\cite{xu2008satzilla,xu2010hydra,hoos2014claspfolio,lindauer2015autofolio,khudabukhsh2016satenstein}, optimization~\cite{de2009frankenstein,dubois2011automatic,lopez2012automatic,mascia2014grammar,liao2014unified,BezLopStu2016tec}, control~\cite{francesca2014automode,francesca2015automode,hasselmann2018automatic}, and, more recently, machine learning~\cite{autoweka,komer2014hyperopt,auto-sklearn,autonet,kotthoff2017auto,google-evonn,google-rl}. Indeed, automated machine learning~(AutoML) is a fast-expanding field due to the joint efforts from industry and academia, with a number of software packages being made available every year~\cite{autoweka,komer2014hyperopt,auto-sklearn,OlsonGECCO2016,hyperas}.
%
%In this section, we first discuss background concepts particularly related to AutoML, and later discuss our vanilla package, \isklearn.
%
\subsection{Automated Machine Learning}

Automated machine learning~(AutoML) is a fast-expanding field, largely due to the joint efforts from industry and academia. Yet, its seminal works date from over two decades ago~(e.g., \cite{RonSch1994}), and range from the research on evolutionary algorithms~(EAs) to the research on neural networks. Indeed, the more recent, abrupt expansion in AutoML is largely due to the groundbreaking results achieved by deep learning algorithms~\cite{LeCBenGeo2015dl}. Effectively, these results have both~(i)~drawn the attention of the industry to the efficacy of machine learning, and~(ii)~demonstrated the challenge in designing and configuring predictors.
Since AutoML initiatives stem from diverse research fields, an exhaustive review is beyond the scope of this paper. Below, we focus our discussion on the most important aspects of the main families of approaches from the literature:
% In \textbf{neuroevolution}, evolutionary algorithms evolve the topology and/or parameters of neural networks~\cite{}. \textbf{Neural architecture search} approaches also focus on neural networks, but in this case networks are used to train and/or configure other networks.

\textbf{Algorithm configuration} approaches often model the AutoML task as the CASH problem, i.e., \emph{combined algorithm selection and hyperparameter optimization}~\cite{autoweka}. In summary, such approaches attempt to select a predictor from a portfolio while simultaneously configuring their associated hyperparameters. The search is conducted by a configurator, typically a heuristic optimization algorithm. The best known works in this field concern Auto-WEKA~\cite{autoweka} and \autosklearn~\cite{auto-sklearn}.

\textbf{Neural architecture search} focuses on the design and configuration of neural networks~\cite{ElsMetHut2019nas-survey}. The AutoML problem is generally modeled as a reinforcement learning problem, where a searching neural network must identify the best target neural network according to a given reward function. Given its focus on neural networks, this research field offers a number of interesting approaches to better address this context.
%, such as parameter sharing~\cite{PhaGuaZopLeDea2018param}.
Indeed, a number of recent breakthroughs in deep learning research are directly related to this field.

\textbf{Neuroevolution}~\cite{StaMii2002neat,google-evonn,LuWhaBodDheDebGooBan2019nsganet} is closely related to the research on both algorithm configuration and neural architecture search. In particular, neuroevolution approaches use EAs to evolve the topology and/or parameters of neural networks. The most emblematic algorithm from this field is likely NEAT~\cite{StaMii2002neat}, and the interest in this topic has been strongly stirred by the industry~\cite{google-evonn}. More recently, multi-objective neuroevolution has targeted efficacy and efficiency as prototypical, conflicting objectives to be simultaneously optimized~\cite{LuWhaBodDheDebGooBan2019nsganet}.

A few important works do not fit our taxonomy. Yet, we believe our brief review is important for the discussion on algorithm configuration we conduct next. More importantly, it highlights the diversity in approaches that have been proposed over the years, and how challenging it would be to properly benchmark them.

\subsection{Algorithm Configuration}

Algorithm configuration is currently better understood as automated algorithm engineering, a growing field that comprehends different tasks, such as selection, configuration, design, and analysis~\cite{BezerraPhD}. The prominent results obtained by these approaches span over a wide range of application domains, such as decision~\cite{khudabukhsh2016satenstein}, optimization~\cite{BezerraPhD}, control~\cite{hasselmann2018automatic}, and, more recently, machine learning~\cite{autoweka,auto-sklearn}. 

In the context of AutoML, approaches to CASH generally combine a configuration (i)~\emph{space} and (ii)~\emph{setup}. A configuration space is defined in terms of a meta-description of an algorithmic portfolio, e.g. a template or a grammar. 
Examples are the templates proposed for Auto-WEKA~\cite{autoweka} and \autosklearn~\cite{auto-sklearn}, respectively built on WEKA and scikit-learn. 
In addition, since the predictors and other components of a machine learning pipeline present hyperparameters, a configuration space must also comprise the valid domains for their configuration. 

Complementarily, the configuration setup is the definition of an experimental setup to evaluate candidates. In more detail, AutoML approaches powered by configurators search the configuration space by sampling candidate configurations. Navigation of the search space is guided by the performance of these candidates, and hence a proper definition of a configuration setup is critical to the performance of the AutoML approach. The most important factors regarding setup concern the~(i)~problem samples provided; (ii)~performance metric adopted, and; (iii)~resource limits allowed. 
Further discussion on each of these topics is provided in Section~\ref{sec:isklearn}.
%In the literature, sampling from the dataset has been done through k-fold cross validation, with a candidate configuration being evaluated through holdout on a single fold.

Given the role of configurators, it is important to remark the contrast between the large number of configurators proposed in the algorithm configuration literature and the small number of configurators adopted in AutoML research. One likely explanation is their background, since many configurators were proposed in the context of search optimization and their application to machine learning is non-trivial.
In general, algorithm configurators can be classified as \emph{model-based} or \emph{model-free}~\cite{BezLopStu2020}. The former attempt to identify promising regions of the configuration space by modeling the relationship between hyperparameters and performance. This is the case with SMAC~\cite{smac}, which powers Auto-WEKA and \autosklearn; and \irace, not yet applied to AutoML. Alternatively, model-free applications identify promising configurations using stochastic local search or randomized sampling~(e.g, HyperBand, \cite{li2017hyperband}).

\subsection{\irace}

\irace is an \emph{estimation of distribution algorithm}~(EDA), a family of EAs that  
%the literature. EDAs differ from most EAs by combining 
combine search aspects from both optimization and learning. At each iteration, \irace mantains a population of candidates, a dual-nature representation of configurations. Specifically, each candidate $c_i$ alive during a given iteration comprises a set of probability distributions $P_i(\phi_j)$, one distribution for each hyperparameter $\phi_j$ of the target algorithm. Complementarily, each candidate $c_i$ is evaluated based on a concrete configuration sampled from $P_i(\phi_j)$ when the candidate is first created. 

The key idea in EDAs is to evolve these probability distributions, which \irace accomplishes by~(i)~\emph{racing} the concrete configurations alive in a given iteration, and; (ii)~updating the probability distributions between iterations based on the surviving candidates. In the racing mechanism, configurations are iteratively run on problem instances and the worst-performing ones are discarded as enough statistical evidence is collected. Through racing, \irace is able to promote \emph{sharpening}, i.e., candidate configurations that perform best get discarded last, meaning there is more available evidence by the time \irace must decide between configurations that perform similarly well.%

An iteration finishes when either a minimum number of surviving candidate configurations or a maximum resource limit is reached. Between iterations, \irace produces offspring candidates from the surviving candidates. An offspring candidate presents probability distributions that have been adjusted to better reflect the concrete configuration from its parent, given the good performance of that concrete configuration in the previous iteration. To reduce variability between iterations, offspring candidates are first evaluated on the same problem instances used to evaluate the surviving candidates of the previous iterations. Finally, \irace may partially restart the population to prevent premature convergence. %from converging prematurely to a region of the search space.

The effectiveness of \irace has been repeatedly demonstrated on diverse application domains~\cite{BezerraPhD}. Besides its effectiveness, the best feature \irace brings is the flexibility in the definition of the configuration space and setup. Concerning the former, \irace was one of the first configurators able to couple with numerical and categorical hyperparameters, and with their dependencies. Regarding the configuration setup, \irace has been applied to domains as diverse as dynamic and multi-objective optimization. Yet, these effective results were a product of carefully, manually designed setups. This is likely the reason why no application of \irace to the context of automated machine learning can be identified in the literature.%, which we propose and assess in the next section. 

\subsection{Contrasting Algorithms}
Though \irace is the focus of this work, we provide further discussion on how it compares to the two most relevant algorithm configurators employed in the ML literature, i.e., SMAC~\cite{smac} and HyperBand~\cite{li2017hyperband}. Both racing and sharpening are standard techniques in the algorithm configuration literature~\cite{BezLopStu2020}, and each configurator proposes a different approach to achieve them. SMAC is a sequential model-based approach, i.e., a surrogate model is used to reduce the number of actual evaluations performed. When racing, candidate configurations are evaluated based on the surrogate model, and sharpening is performed by comparing the configuration obtained from the model search with the best current configuration. SMAC and \irace are alike in being model-based, as previously discussed. Yet they differ in that SMAC is inherently sequential, whereas \irace uses parallelization to a large extent.

HyperBand~\cite{li2017hyperband} represents a model-free paradigm, using a massively parallel racing of candidate configurations. Sharpening is promoted by probing configurations with reduced budgets, i.e., training configurations for increasingly longer periods. Since model-based learning is not employed, the candidate configurations in HyperBand are completely independent, which allows for a parallelization level unmatched by model-based configurators. However, sharpening is only effective in HyperBand as long as the dataset investigated presents a strong correlation between performance for varying training budgets, which is not always the case in ML~\cite{ying2019nasbench}.

In a sense, \irace represents a compromise paradigm between SMAC and HyperBand, as it uses model-based learning but is still parallelizable. Though other approaches bridging these properties have been proposed recently~\cite{falkner2018bohb}, no fully-functional AutoML tool based on ML pipelines powered by any such configurator can be identified thus far. More strikingly, even a fully-functional HyperBand-based system is not yet available.%
\footnote{Such a system has been proposed in~\cite{autoband}, but it is not publicly available in a fully-functional form.}
In the next section, we seek to fill this gap, proposing an AutoML system using \irace as configurator.